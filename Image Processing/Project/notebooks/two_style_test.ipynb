{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "\n",
    "import sys\n",
    "\n",
    "sys.path.append('../')\n",
    "\n",
    "import src.models as models\n",
    "import src.transform as transform\n",
    "import src.video as video\n",
    "import os\n",
    "import logging\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Init logging\n",
    "logger = logging.getLogger('styleTransfer')\n",
    "logger.setLevel(logging.DEBUG)\n",
    "logger.addHandler(logging.FileHandler(\"my_log.log\", mode='w'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Extraction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully read and saved  26 frames\n"
     ]
    }
   ],
   "source": [
    "# Clean the stuff from the last run\n",
    "video.clean_dir('../res/atla/')\n",
    "n_frames, fps = video.extract_video('../res/atla.mp4', '../res/atla/', n_frames=25)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load Style Img\n",
    "style_img_1 = transform.load_image('../res/style/starry_night.jpg')\n",
    "\n",
    "# Load Style Img 2\n",
    "style_img_2 = transform.load_image('../res/style/mona_lisa.jpg')\n",
    "\n",
    "lamb=1.0"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "assert style_img_1.size() == style_img_2.size()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Running Style Transfer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "vgg19 = models.vgg19(weights=models.vgg_19_default_weights).features.eval()\n",
    "mean = models.vgg19_normalization_mean\n",
    "std = models.vgg19_normalization_std"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\Jackson Paull\\.conda\\envs\\img_proc\\lib\\site-packages\\torch\\utils\\_device.py:62: UserWarning: To copy construct from a tensor, it is recommended to use sourceTensor.clone().detach() or sourceTensor.clone().detach().requires_grad_(True), rather than torch.tensor(sourceTensor).\n",
      "  return func(*args, **kwargs)\n"
     ]
    }
   ],
   "source": [
    "count = 0\n",
    "video.clean_dir('../res/output')\n",
    "for img in tqdm(os.listdir('../res/atla')):\n",
    "    if not img.endswith('.jpg'):\n",
    "        continue\n",
    "\n",
    "    lamb = 1 - count / 25\n",
    "\n",
    "    content_img = transform.load_image(os.path.join('../res/atla', img))\n",
    "    assert content_img.size() == style_img_1.size()\n",
    "\n",
    "    output = transform.run_style_transfer(vgg19, \n",
    "                             mean,\n",
    "                             std,\n",
    "                             content_img,\n",
    "                             style_img_1,\n",
    "                             None,\n",
    "                             lamb=lamb)\n",
    "    output_img = transform.to_PIL(output)\n",
    "    output_img.save(f'../res/output/frame{count:04d}.png')\n",
    "    count +=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Greatest entry with frame < end_frame is the current step. frame\n",
    "keypoints = [\n",
    "    # End Frame, path to style image 1,   path to style image 2,             interpolation function\n",
    "    (1000,      'path_to_img_1',        'path_2_img_2',        '<lambda func dependent upon frame number>'),\n",
    "    (2000),\n",
    "    (3000),\n",
    "    (4000),\n",
    "    (5000),\n",
    "    (6000),\n",
    "    (7000),\n",
    "    (8000),\n",
    "    (-1) # Until the end\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Video Encoding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "video.encode_video('../res/output', '../output.mp4', fps=fps)\n",
    "\n",
    "# Don't need to store the video in a lossy format 3 times\n",
    "video.clean_dir('../res/atla')\n",
    "video.clean_dir('../res/output')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_proc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
