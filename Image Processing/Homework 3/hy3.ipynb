{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Homework 3 \n",
    "Author - Jackson Paull\n",
    "Date - 19 October 2023"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from PIL import Image\n",
    "import itertools\n",
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_image(path: str, dtype='float', convert_grayscale=True, transform=None):\n",
    "    img = Image.open(path)\n",
    "    img.load()\n",
    "    img = np.asarray(img, dtype)\n",
    "    if dtype=='float':\n",
    "        img = img / 255\n",
    "    if convert_grayscale:\n",
    "        img = img.mean(axis=-1).astype(dtype)\n",
    "    if transform is not None:\n",
    "        img = transform(img)\n",
    "    return img"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 1: Band-Pass Filtering\n",
    "\n",
    "The goal of this problem is to implement a band-pass filter using two Gaussian filters. The DoG\n",
    "filter (The Difference of Gaussian) is defined as the difference of two Gaussian kernels with\n",
    "different variances ùúé1 and ùúé2. For simplicity, let ùúé2 = ùëò ùúé1 for some k and subtract the Gaussian\n",
    "kernel with variance ùúé1 from the kernel with ùúé2. (Helpful functions: getGaussianKernel,\n",
    "plot_surface, copyMakeBorder, filter2D)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\n",
    "You need to write a 2d-DoG function, ‚ÄúmyDoG(DoGsize, sigma1, k)‚Äù. This function produces a kernel of size DoGsize that is the difference of two gaussian kernels\n",
    "with corresponding variances ùúé1 and ùúé2 = ùëò ùúé1."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def myDoG(DoGsize, sigma1, k):\n",
    "    sigma2 = k * sigma1\n",
    "\n",
    "    k1 = cv2.getGaussianKernel(DoGsize, sigma1) * np.sqrt(2 * np.pi * sigma1 **2)\n",
    "    k1 = np.dot(k1, k1.T)\n",
    "    k2 = cv2.getGaussianKernel(DoGsize, sigma2) * np.sqrt(2 * np.pi * sigma2 **2)\n",
    "    k2 = np.dot(k2, k2.T)\n",
    "\n",
    "    return k2 - k1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "Use this function to generate four 2d-DoG filters with ùúé1 = 1, 2, 3, 4, k = 1.5, and a window size ten times ùúé1. Show the 3d illustration of the four 2d-DoG filters in a\n",
    "2x2 grid with appropriate labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filters = []\n",
    "for s in np.arange(1, 5):\n",
    "    DoGsize = 10 * s\n",
    "    filters.append(myDoG(DoGsize, s, 1.5))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "fig, axs = plt.subplots(2, 2, subplot_kw={'projection':'3d'})\n",
    "fig.suptitle('Problem 1: Part b)')\n",
    "\n",
    "for i, f in enumerate(filters):\n",
    "    ax = axs[i // 2, i % 2]\n",
    "\n",
    "    Z = filters[i]\n",
    "\n",
    "    X = np.arange(Z.shape[0])\n",
    "    Y = np.column_stack([X] * Z.shape[1])\n",
    "    X = np.row_stack([X] * Z.shape[0])\n",
    "    ax.plot_surface(X, Y, Z)\n",
    "    ax.set_title(f'$\\sigma_1 = {i + 1}$')\n",
    "\n",
    "fig.tight_layout()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) \n",
    "Read in cars.jpg and convert it to gray-scale. Generate the same four 2d-DoG filters as in part b. Apply the filters to cars.jpg using a method of your choosing (recall the\n",
    "methods used in HW2). Display the filtered images in a 2x2 grid with the appropriate\n",
    "labels. Write a few lines on what you observe, and why."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "cars = load_image('./Images/cars.jpg')\n",
    "fix, axs = plt.subplots(2, 2)\n",
    "fig.suptitle('Problem 1: Part c)')\n",
    "\n",
    "for i, f in enumerate(filters):\n",
    "    ax = axs[i // 2, i % 2]\n",
    "    ax.axis('off')\n",
    "    ax.set_title(f'$\\sigma_1 = {i+1}$')\n",
    "\n",
    "    img = cv2.filter2D(cars, -1, f)\n",
    "    ax.imshow(img, cmap='gray')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we can see that as $\\sigma_1$ increases we get a greater \"blurring\" effect. This is due to the kernel values being more uniformly distributed over a wider range, so a given pixel will have its value modified more significantly by its neighbors.\n",
    "\n",
    "Interestingly, in all cases, this specific band pass filter will yield an image for which $J(i, j)$ does not depend at all on $I(i, j)$, since the kernel has a value of 0 at its center"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 2: Non Local (NL) Means\n",
    "\n",
    "Here we will be looking at the application of Non-Local Means in removing noise. Helpful\n",
    "functions: skimage.util.view_as_windows, scipy.spatial.distance.cdist, padarray, im2col, pdist2,\n",
    "sum, reshape."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a) \n",
    "\n",
    "You need to read bird.jpg, convert it to grayscale, and resize the image so that\n",
    "it is a perfect square. Display this resulting image."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "bird = load_image('./Images/bird.jpg', transform= lambda x: np.pad(x, ((1, 0), (0,0))))\n",
    "plt.imshow(bird, cmap='gray')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b) \n",
    "\n",
    "You will now calculate the Luminance Similarity Measure ‚ÄúW(m,i)‚Äù between all\n",
    "the 3x3 square windows in the image, using the information given in Module 5 slide 14\n",
    "onwards. Use Kw = 1 and ùúéw = 1. Normalize ‚ÄúW(m, i)‚Äù so that the sum across each row is\n",
    "equal to 1.0. Note that even though this is a small image, this step will likely take a while\n",
    "to execute (a few minutes depending on hardware)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def lum_sim_measure(img, Kw=1, sigw=1, window_size=3):\n",
    "    all_pixels = np.array(list(itertools.product(np.arange(img.shape[0]), np.arange(img.shape[1]))))\n",
    "    W = np.zeros(tuple(itertools.chain(img.shape, img.shape)))\n",
    "\n",
    "    img = cv2.copyMakeBorder(img, \n",
    "                                window_size//2,\n",
    "                                window_size//2,\n",
    "                                window_size//2,\n",
    "                                window_size//2,\n",
    "                                borderType=cv2.BORDER_DEFAULT)\n",
    "    for m, n in tqdm(all_pixels):\n",
    "        for i, j in all_pixels:\n",
    "            if W[m, n, i, j] != 0:\n",
    "                # Matrix has a hyperplane of symettry, so we can skip computation\n",
    "                W[i, j, m, n] = W[m, n, i, j]\n",
    "                continue\n",
    "            wi = img[i:i+window_size, j:j+window_size]\n",
    "            wm = img[m:m+window_size, n:n+window_size]\n",
    "            w = np.sum(np.square(wi - wm))\n",
    "            W[i, j, m, n] = Kw * np.exp(-w/(sigw**2))\n",
    "\n",
    "    return W"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "W_unnorm = lum_sim_measure(bird)\n",
    "W = W_unnorm / W_unnorm.sum(axis=(0,1)) # Normalize"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\n",
    "\n",
    "From all the windows, we will now compare the similarity measure images\n",
    "generated between choosing two different windows in the image. For this part, take the\n",
    "3x3 window in the top-left corner of the image, and reshape it to a 3x3 matrix. Take the\n",
    "first row in W which corresponds to all of the pair-wise distances to that 3x3 window, and\n",
    "reshape it to the size of the image. Display the resulting window and image side by side\n",
    "with appropriate labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "window = img[0:3, 0:3]\n",
    "distances = W[0,0,:,:]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Problem 2: Part c)')\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "ax1.imshow(window, cmap='gray')\n",
    "ax1.axis(False)\n",
    "ax1.set_title('Window')\n",
    "\n",
    "ax2.imshow(distances, cmap='gray')\n",
    "ax2.axis(False)\n",
    "ax2.set_title('Distances to Other Windows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d) \n",
    "\n",
    "You will now need to repeat the same operation you did in part c), but by\n",
    "taking the 3x3 window in the middle of the left side of the image. Display the resulting\n",
    "window and the original image side by side with appropriate labels."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "h = img.shape[1] // 2 # Middle of image\n",
    "\n",
    "window = img[0:3, h: h + 3]\n",
    "distances = W[0,h,:,:]\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Problem 2: Part c)')\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "ax1.imshow(window, cmap='gray')\n",
    "ax1.axis(False)\n",
    "ax1.set_title('Window')\n",
    "\n",
    "ax2.imshow(distances, cmap='gray')\n",
    "ax2.axis(False)\n",
    "ax2.set_title('Distances to Other Windows')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)\n",
    "Using the luminance similarity measure, perform Non Local (NL) Means\n",
    "filtering on bird.jpg, and remove the noise. Display the resulting image and the original\n",
    "image in a 2x1 grid with appropriate results. Comment a few lines on the result achieved.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def NL_filter(img, weights):\n",
    "    return (img * weights).sum(axis=(2,3))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "filtered = NL_filter(bird, W)\n",
    "\n",
    "\n",
    "fig = plt.figure()\n",
    "fig.suptitle('Problem 2: Part c)')\n",
    "ax1 = fig.add_subplot(1, 2, 1)\n",
    "ax2 = fig.add_subplot(1, 2, 2)\n",
    "\n",
    "ax1.imshow(bird, cmap='gray')\n",
    "ax1.axis(False)\n",
    "ax1.set_title('Original')\n",
    "\n",
    "ax2.imshow(filtered, cmap='gray')\n",
    "ax2.axis(False)\n",
    "ax2.set_title('Filtered')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 3: Block Truncation Coding (BTC)\n",
    "\n",
    "BTC is a fast and lossy compression technique. In this problem, we will understand how BTC is\n",
    "used, along with its advantages and disadvantages. 4x4 blocks are used where applicable in\n",
    "the following sub-problems. You can use the following link to learn more about BTC:\n",
    "https://en.wikipedia.org/wiki/Block_Truncation_Coding#Encoder . Helpful functions: col2im,\n",
    "im2col, bi2de, de2bi"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\n",
    "\n",
    "You should read bevo.jpg, and make it grayscale. Resize the image by a factor\n",
    "of ¬Ω to make the compression faster. Resize the image further such that the height and\n",
    "width of the images are both multiples of 4; such that it is still roughly the same\n",
    "dimensions as ¬Ω of the original image dimensions. Display the grayscale compressed\n",
    "image.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "\n",
    "Write a function to compute the mean and standard deviation of a 4x4 block\n",
    "with ‚ÄòB1‚Äô bits to compute and store the mean, and ‚ÄòB2‚Äô bits to compute and store the\n",
    "standard deviation; where ‚ÄòB1‚Äô and ‚ÄòB2‚Äô are input parameters to the function. Hint: you\n",
    "might need to compute the mean and standard deviation values, and then truncate in the\n",
    "end based on ‚ÄòB1‚Äô and ‚ÄòB2‚Äô parameter values."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c)\n",
    "\n",
    "Write a function to compute the 4x4 BTC binary block by thresholding the input\n",
    "4x4 image block at the mean. Pass bevo.jpg through this function for 3 different ‚ÄòB1‚Äô, ‚ÄòB2‚Äô\n",
    "settings; {2,1}, {3,3}, and {7,5}. Compute the BTC binary blocks image for bevo.jpg, and\n",
    "display the 3 images in a 3x1 grid with appropriate labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### d)\n",
    "\n",
    "Write a function to decode a 4x4 BTC binary block given the mean and\n",
    "standard deviation as the input parameters, and get back the original 4x4 image block.\n",
    "Pass the 3 BTC binary block images generated in part c) through this function, for the\n",
    "aforementioned ‚ÄòB1‚Äô, ‚ÄòB2‚Äô settings; and get back the 3 decompressed bevo.jpg images.\n",
    "Display these three images along with the original image in a 2x2 grid with appropriate\n",
    "labels."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### e)\n",
    "\n",
    "Compute and report the compression ratios for the 3 BTC encoded images\n",
    "generated"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Question 4: VGG19 Feature Extractoin\n",
    "\n",
    "VGG19 is a convolutional neural network architecture used primarily for image classification.\n",
    "The network is primarily composed of 3x3 convolutional filters, making it effective at capturing\n",
    "intricate and abstract features in images. In this problem we will utilize a pre-trained VGG19\n",
    "network to extract features maps from an image. These features can be very useful for other\n",
    "applications; for example, you can compare two images by comparing their corresponding\n",
    "extracted feature maps instead of using their original representations which can help highlight\n",
    "perceptually relevant differences. For more on this see https://arxiv.org/pdf/1603.08155.pdf\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### a)\n",
    "\n",
    "Download and load a pre-trained version of the VGG19 model. Most machine\n",
    "learning frameworks should have a way to download and use pre-trained networks\n",
    "directly. With PyTorch you can use their pretrained model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### b)\n",
    "\n",
    "Read lion.jpg and transform it so that it is suitable for the model. The\n",
    "corresponding transform may depend on the pre-trained version of the model that you\n",
    "are using. For the default version in PyTorch, you will need to resize the image to\n",
    "224x224 and normalize it to the ImageNet dataset mean = [0.485, 0.456, 0.406] and std\n",
    "= [0.229, 0.224, 0.225]. Display the transformed image."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### c) \n",
    "\n",
    "Experiment with passing the transformed image through layers of the network.\n",
    "Note that you may need to add a dummy batch dimension to the input tensor for the\n",
    "model to accept it. Find three feature maps that look interesting to you and display them.\n",
    "In Pytorch you can get a list of vgg19‚Äôs layers by accessing its features field. Then you\n",
    "can use slicing to use only a subset of these layers and get the results of passing your\n",
    "input through them.\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "img_proc",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
